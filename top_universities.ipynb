{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you haven't already created an activated a virtual environment for this notebook, run this cell\n",
    "# !python3 -m venv venv3\n",
    "# !source venv/bin/activate\n",
    "\n",
    "# !%pip install scrapy==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import urllib.request\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######IMPORTANT  Apparently the web site \"https://edurank.org/geo/ca/\" detects scraping \n",
    "# and changes the configuration of the page!!!!!!!!\n",
    "#### Download the page ONCE. If you download it again the page might be different that the\n",
    "# one previously downloaded!!!!!!!\n",
    "\n",
    "url5=\"https://edurank.org/geo/ca/\"\n",
    "\n",
    "url_response = requests.get(url5)\n",
    "url_contents = url_response.text\n",
    "\n",
    "#print(url_contents[0:300])\n",
    "\n",
    "with open (\"universities2.html\",\"w\") as file:  ###carefull\n",
    "\n",
    "    file.write(url_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import os\n",
    "\n",
    "current_dir = os.path.abspath('')\n",
    "# url = os.path.join(current_dir, \"universities2.html\")\n",
    "\n",
    "#pathX=\"C:\\\\cygwin64\\\\home\\\\cc\\\\vscode\\\\universities.html\"\n",
    "\n",
    "pathX=\"C:\\\\cygwin64\\\\home\\\\cc\\\\vscode\\\\universities.html\"\n",
    "with open(pathX) as _f:\n",
    "    url_data = _f.read()\n",
    "\n",
    "response = scrapy.http.TextResponse(pathX, body=url_data, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_li=response.xpath('//ol')\n",
    "len(list_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "ol=  0 total li=  3\n",
      "ol=  1 total li=  100\n"
     ]
    }
   ],
   "source": [
    "list_ol=response.xpath('//ol') ## ordered lists(<ol>)  (<li>) tag defines a list item.\n",
    "print(len(list_ol))\n",
    "\n",
    "\n",
    "for i in range(len(list_ol)):\n",
    "    print(\"ol= \",i, \"total li= \",len(list_ol[i].xpath('li')) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use second ol to get the <li>s\n",
    "\n",
    "list_li= list_ol[1].xpath('li')\n",
    "len(list_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_li[10:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University of Toronto', 'University of British Columbia', 'McGill University', 'University of Alberta', 'University of Waterloo', 'University of Montreal', 'Simon Fraser University', 'McMaster University', 'University of Calgary', 'Western University']\n"
     ]
    }
   ],
   "source": [
    "# university names are located in li/div/div/div/h2/a  \n",
    "u_names=list_li[0:10].xpath(\"div/div/div/h2/a/text()\").extract()\n",
    "print(u_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ontario', 'British Columbia', 'Quebec', 'Alberta', 'Ontario', 'Quebec', 'British Columbia', 'Ontario', 'Alberta', 'Ontario']\n",
      "['Toronto', 'Vancouver', 'Montreal', 'Edmonton', 'Waterloo', 'Montreal', 'Burnaby', 'Hamilton', 'Calgary', 'London']\n"
     ]
    }
   ],
   "source": [
    "#university location is located in div/div/div/div/a/span/ \n",
    "\n",
    "province=list_li.xpath(\"div/div/div/div/a[1]/span/text()\")[0:10].extract()\n",
    "print(province)\n",
    "\n",
    "city=list_li.xpath(\"div/div/div/div/a[2]/span/text()\")[0:10].extract()\n",
    "print(city)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "['17', '33', '46', '76', '105', '115', '121', '127', '137', '138']\n"
     ]
    }
   ],
   "source": [
    "rank_can=list_li.xpath(\"div/div/div[2]/ul/li[1]/span/text()\")[0:10].extract()\n",
    "print(rank_can)\n",
    "\n",
    "rank_world=list_li.xpath(\"div/div/div[2]/ul/li[3]/span/text()\")[0:10].extract()\n",
    "print(rank_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['43%', '53%', '47%', '58%', '53%', '45%', '59%', '59%', '15%', '31%']\n",
      "['84,556', '59,659', '40,036', '37,500', '35,900', '45,360', '32,500', '30,117', '27,500', '27,300']\n",
      "['1827', '1908', '1821', '1908', '1957', '1878', '1965', '1887', '1966', '1878']\n"
     ]
    }
   ],
   "source": [
    "acceptance_rate=list_li.xpath(\"div/div/div[4]/dl/div[1]/dd/text()\")[0:10].extract()\n",
    "print(acceptance_rate)\n",
    "\n",
    "enrollment=list_li.xpath(\"div/div/div[4]/dl/div[2]/dd/text()\")[0:10].extract()\n",
    "print(enrollment)\n",
    "\n",
    "founded= list_li.xpath(\"div/div/div[4]/dl/div[3]/dd/text()\")[0:10].extract()\n",
    "print(founded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"rank_canada\",\"rank_world\",\"univercity\",\"city\",\"province\", \n",
    "\"accept_rate\",\"enrollment\",\"founded\"]\n",
    "\n",
    "rows=[]\n",
    "for i in range(len(u_names)):\n",
    "    rows.append([rank_can[i],rank_world[i],u_names[i], city[i], province[i],    \n",
    "    acceptance_rate[i],enrollment[i],founded[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_universities.csv\", \"w\") as _f:\n",
    "    writer = csv.writer(_f)\n",
    "\n",
    "    # write the column names\n",
    "    writer.writerow(columns)\n",
    "\n",
    "    # now write the rows\n",
    "    writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0303190f1c8c691fa9994d3c799a212d90e80d675371cad4184da4200e89748e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
